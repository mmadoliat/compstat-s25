---
title: "Computational Statistics"
subtitle: "Chapter 14 - Optimization"
title-slide-attributes:
  data-background-image: mu-bg.png
  data-background-size: stretch
  data-slide-number: none
format: revealjs
---

# Lecture 1: One-Dimensional Optimization (Part 1)

## Introduction to Optimization

-   Overview of optimization methods
-   Example: One-dimensional optimization using `optimize`

```{r}
f <- function(x) log(x + log(x)) / log(1 + x)

# Plotting the function
curve(f(x), from = 2, to = 15, ylab = "f(x)")

# Finding the maximum
res <- optimize(f, lower = 4, upper = 8, maximum = TRUE)
abline(v=res$maximum)
res$maximum
```

## Visualizing Optimization Results

```{r}
# Add a line indicating the maximum
abline(v=res$maximum, col = "red", lwd = 2)
```

# Lecture 2: Maximum Likelihood Estimation (Part 2)

## Introduction to MLE

-   Introduction to Maximum Likelihood Estimation (MLE)
-   Example: MLE for Gamma distribution

```{r}
# MLE for Gamma distribution
m <- 20000
est <- matrix(0, m, 2)
n <- 2000
r <- 5
lambda <- 2

obj <- function(lambda, xbar, logx.bar) {
  r <- length(xbar)
  log(lambda) - lambda * mean(xbar) + logx.bar
}
```

## Optimizing MLE

```{r}
# Optimizing the MLE
xbar <- rnorm(n, mean = r/lambda, sd = 1)
logx.bar <- mean(log(xbar))
result <- optimize(obj, lower = 1, upper = 10, xbar = xbar, logx.bar = logx.bar, maximum = TRUE)
result
```

## Conclusion

-   Recap of one-dimensional optimization and MLE techniques
-   Practice: Apply optimization to other statistical problems and models
